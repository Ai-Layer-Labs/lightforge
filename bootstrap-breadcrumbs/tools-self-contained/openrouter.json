{
  "schema_name": "tool.code.v1",
  "title": "OpenRouter LLM Tool (Self-Contained)",
  "tags": ["tool", "tool:openrouter", "workspace:tools", "self-contained", "llm"],
  "context": {
    "name": "openrouter",
    "description": "OpenRouter - Access to 100+ LLM models via unified API with real pricing",
    "version": "2.0.0",
    "code": {
      "language": "typescript",
      "source": "/**\n * OpenRouter LLM Tool - Self-Contained Deno Version\n * Accesses 100+ models with real pricing\n */\n\ninterface Message {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n\ninterface Input {\n  messages: Message[];\n  model?: string;\n  temperature?: number;\n  max_tokens?: number;\n  config_id?: string;\n}\n\ninterface Output {\n  content: string;\n  model: string;\n  usage: {\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n  };\n  cost_estimate: number;\n}\n\ninterface Context {\n  secrets: Record<string, string>;\n  api: any;\n  request: any;\n}\n\nexport async function execute(input: Input, context: Context): Promise<Output> {\n  // Validate input\n  if (!input.messages || !Array.isArray(input.messages) || input.messages.length === 0) {\n    throw new Error('messages array is required and must not be empty');\n  }\n  \n  // Get config from breadcrumb if config_id provided\n  let config: any = {};\n  if (input.config_id || context.request.trigger_event?.context?.config_id) {\n    const configId = input.config_id || context.request.trigger_event?.context?.config_id;\n    try {\n      const configBreadcrumb = await context.api.getBreadcrumb(configId);\n      if (configBreadcrumb.schema_name === 'tool.config.v1') {\n        config = configBreadcrumb.context.config || {};\n      }\n    } catch (error) {\n      console.warn(`Failed to load config from ${configId}:`, error);\n    }\n  }\n  \n  // Get API key from secrets\n  const apiKey = context.secrets['OPENROUTER_API_KEY'];\n  if (!apiKey) {\n    throw new Error('OPENROUTER_API_KEY not found in secrets');\n  }\n  \n  // Determine model (input overrides config)\n  const model = input.model || config.defaultModel || 'google/gemini-2.0-flash-exp';\n  const temperature = input.temperature ?? config.temperature ?? 0.7;\n  const maxTokens = input.max_tokens || config.maxTokens || 4000;\n  \n  // Call OpenRouter API\n  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {\n    method: 'POST',\n    headers: {\n      'Authorization': `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n      'HTTP-Referer': 'http://localhost:3000',\n      'X-Title': 'RCRT Agent System'\n    },\n    body: JSON.stringify({\n      model,\n      messages: input.messages,\n      temperature,\n      max_tokens: maxTokens\n    })\n  });\n  \n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(`OpenRouter API error ${response.status}: ${errorText}`);\n  }\n  \n  const data = await response.json();\n  \n  // Calculate cost using models catalog\n  let costEstimate = 0;\n  try {\n    const catalogResults = await context.api.searchBreadcrumbs({\n      schema_name: 'openrouter.models.catalog.v1',\n      tag: 'openrouter:models'\n    });\n    \n    if (catalogResults.length > 0) {\n      const catalog = catalogResults[0];\n      const modelInfo = catalog.context.models?.find((m: any) => m.id === model);\n      \n      if (modelInfo?.pricing) {\n        const promptCost = (data.usage?.prompt_tokens || 0) * parseFloat(modelInfo.pricing.prompt);\n        const completionCost = (data.usage?.completion_tokens || 0) * parseFloat(modelInfo.pricing.completion);\n        costEstimate = promptCost + completionCost;\n      }\n    }\n  } catch (error) {\n    console.warn('Failed to calculate cost from catalog:', error);\n    // Fallback estimate\n    const totalTokens = data.usage?.total_tokens || 0;\n    costEstimate = (totalTokens / 1000) * 0.005; // $5 per 1M tokens default\n  }\n  \n  return {\n    content: data.choices[0].message.content,\n    model: data.model,\n    usage: data.usage || {\n      prompt_tokens: 0,\n      completion_tokens: 0,\n      total_tokens: 0\n    },\n    cost_estimate: costEstimate\n  };\n}\n"
    },
    "input_schema": {
      "type": "object",
      "properties": {
        "messages": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "role": {
                "type": "string",
                "enum": ["system", "user", "assistant"]
              },
              "content": {
                "type": "string"
              }
            },
            "required": ["role", "content"]
          },
          "description": "Array of chat messages",
          "minItems": 1
        },
        "model": {
          "type": "string",
          "description": "Model to use (e.g., 'google/gemini-2.0-flash-exp', 'anthropic/claude-3-haiku')"
        },
        "temperature": {
          "type": "number",
          "description": "Sampling temperature (0-2)",
          "minimum": 0,
          "maximum": 2
        },
        "max_tokens": {
          "type": "number",
          "description": "Maximum tokens in response",
          "minimum": 1
        },
        "config_id": {
          "type": "string",
          "description": "Optional tool.config.v1 breadcrumb ID for configuration"
        }
      },
      "required": ["messages"]
    },
    "output_schema": {
      "type": "object",
      "properties": {
        "content": {
          "type": "string",
          "description": "The AI-generated response"
        },
        "model": {
          "type": "string",
          "description": "Model that generated the response"
        },
        "usage": {
          "type": "object",
          "properties": {
            "prompt_tokens": { "type": "number" },
            "completion_tokens": { "type": "number" },
            "total_tokens": { "type": "number" }
          },
          "description": "Token usage statistics"
        },
        "cost_estimate": {
          "type": "number",
          "description": "Estimated cost in USD"
        }
      },
      "required": ["content", "model", "usage"]
    },
    "permissions": {
      "net": ["openrouter.ai"],
      "read": false,
      "write": false,
      "env": false,
      "run": false,
      "ffi": false,
      "hrtime": false
    },
    "limits": {
      "timeout_ms": 60000,
      "memory_mb": 128,
      "cpu_percent": 50
    },
    "required_secrets": ["OPENROUTER_API_KEY"],
    "ui_schema": {
      "configurable": true,
      "config_fields": [
        {
          "key": "apiKey",
          "label": "API Key",
          "type": "secret",
          "ui_type": "secret-select",
          "description": "OpenRouter API key for authentication",
          "required": true,
          "secret_name": "OPENROUTER_API_KEY",
          "placeholder": "Select a secret...",
          "help_text": "ðŸ’¡ Recommended secret name: OPENROUTER_API_KEY"
        },
        {
          "key": "defaultModel",
          "label": "Default Model",
          "type": "string",
          "ui_type": "select",
          "description": "Default model when none specified in request",
          "default_value": "google/gemini-2.0-flash-exp",
          "required": false,
          "options_source": {
            "type": "breadcrumb-search",
            "schema_name": "openrouter.models.catalog.v1",
            "tag": "openrouter:models",
            "value_path": "$.context.models[*].id",
            "label_path": "$.context.models[*].name"
          }
        },
        {
          "key": "maxTokens",
          "label": "Max Tokens",
          "type": "number",
          "ui_type": "number",
          "description": "Maximum tokens per response",
          "default_value": 4000,
          "required": false,
          "validation": {
            "min": 1,
            "max": 32000
          }
        },
        {
          "key": "temperature",
          "label": "Temperature",
          "type": "number",
          "ui_type": "slider",
          "description": "Response creativity (0.0 - 2.0)",
          "default_value": 0.7,
          "required": false,
          "validation": {
            "min": 0.0,
            "max": 2.0,
            "step": 0.1
          }
        }
      ]
    },
    "examples": [
      {
        "description": "Simple question",
        "input": {
          "messages": [
            { "role": "user", "content": "What is 2+2?" }
          ]
        },
        "output": {
          "content": "2 + 2 equals 4.",
          "model": "google/gemini-2.0-flash-exp",
          "usage": { "prompt_tokens": 10, "completion_tokens": 8, "total_tokens": 18 },
          "cost_estimate": 0.00001
        },
        "explanation": "Access the response with result.content. Model and usage info available."
      },
      {
        "description": "With system prompt and temperature",
        "input": {
          "messages": [
            { "role": "system", "content": "You are a helpful coding assistant" },
            { "role": "user", "content": "How do I create a list in Python?" }
          ],
          "temperature": 0.7
        },
        "output": {
          "content": "In Python, you can create a list using square brackets: my_list = [1, 2, 3]",
          "model": "google/gemini-2.0-flash-exp",
          "usage": { "prompt_tokens": 25, "completion_tokens": 20, "total_tokens": 45 },
          "cost_estimate": 0.00003
        },
        "explanation": "System prompts guide behavior. Temperature controls creativity (0-2)."
      },
      {
        "description": "Specify different model",
        "input": {
          "messages": [
            { "role": "user", "content": "Explain quantum computing" }
          ],
          "model": "anthropic/claude-3-haiku",
          "max_tokens": 500
        },
        "output": {
          "content": "Quantum computing uses quantum mechanics principles...",
          "model": "anthropic/claude-3-haiku",
          "usage": { "prompt_tokens": 12, "completion_tokens": 108, "total_tokens": 120 },
          "cost_estimate": 0.00015
        },
        "explanation": "Specify a different model with the model parameter. Check models catalog for available options."
      }
    ]
  }
}

